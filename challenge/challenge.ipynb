{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(csv):\n",
    "    file = pd.read_csv(csv)\n",
    "    data = {\n",
    "        'IO_SIZE(Bytes)': file[\"IO_SIZE(Bytes)\"].tolist(),  \n",
    "        'Trial 1 Throughput(MB/s)': file[\"Trial 1 Throughput(MB/s)\"].tolist(),  \n",
    "        'Trial 2 Throughput(MB/s)': file[\"Trial 2 Throughput(MB/s)\"].tolist(),\n",
    "        'Trial 3 Throughput(MB/s)': file[\"Trial 3 Throughput(MB/s)\"].tolist(),  \n",
    "        'Trial 4 Throughput(MB/s)': file[\"Trial 4 Throughput(MB/s)\"].tolist(),  \n",
    "        'Trial 5 Throughput(MB/s)': file[\"Trial 5 Throughput(MB/s)\"].tolist()   \n",
    "    }\n",
    "    return data\n",
    "\n",
    "def read_stride(csv):\n",
    "    file = pd.read_csv(csv)\n",
    "    size_list = file[\"IO_SIZE(Bytes)\"].tolist()\n",
    "    stride_list = file[\"Stride(Bytes)\"].tolist()\n",
    "    result = []\n",
    "    # Choosing to concat size and stride, will fix/separate in post\n",
    "    for a, b in zip(size_list, stride_list):\n",
    "        concatenated = str(a) + \".\" + str(b)\n",
    "        result.append(float(concatenated))\n",
    "    data = {\n",
    "        'IO_SIZE(Bytes)': result,\n",
    "        'Trial 1 Throughput(MB/s)': file[\"Trial 1 Throughput(MB/s)\"].tolist(), \n",
    "        'Trial 2 Throughput(MB/s)': file[\"Trial 2 Throughput(MB/s)\"].tolist(), \n",
    "        'Trial 3 Throughput(MB/s)': file[\"Trial 3 Throughput(MB/s)\"].tolist(), \n",
    "        'Trial 4 Throughput(MB/s)': file[\"Trial 4 Throughput(MB/s)\"].tolist(), \n",
    "        'Trial 5 Throughput(MB/s)': file[\"Trial 5 Throughput(MB/s)\"].tolist()  \n",
    "    }\n",
    "    return data\n",
    "\n",
    "size_read = read('challenge_data/size_read.csv')\n",
    "size_write = read('challenge_data/size_write.csv')\n",
    "random_read = read('challenge_data/random_read.csv')\n",
    "random_write = read('challenge_data/random_write.csv')\n",
    "stride_read = read_stride('challenge_data/stride_read.csv')\n",
    "stride_write = read_stride('challenge_data/stride_write.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_size(data):\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # calculate mean and std\n",
    "    means = df.iloc[:, 1:].mean(axis=1)\n",
    "    stds = df.iloc[:, 1:].std(axis=1)\n",
    "\n",
    "    df['Mean Throughput (MB/s)'] = means\n",
    "    df['Standard Deviation (MB/s)'] = stds\n",
    "\n",
    "    results = df[['IO_SIZE(Bytes)', 'Mean Throughput (MB/s)', 'Standard Deviation (MB/s)']]\n",
    "\n",
    "    # cohen's d definition\n",
    "    def cohens_d(mean, population_mean, std_dev):\n",
    "        return (mean - population_mean) / std_dev\n",
    "\n",
    "    # create list of hypothetical means\n",
    "    hypothetical_means = []\n",
    "    for item in means:\n",
    "        hypothetical_means.append(0.90*item)\n",
    "\n",
    "    cohens_d_values = []\n",
    "    for index, row in df.iterrows():\n",
    "        d_value = cohens_d(row['Mean Throughput (MB/s)'], hypothetical_means[index], row['Standard Deviation (MB/s)'])\n",
    "        cohens_d_values.append(round(d_value,2))\n",
    "\n",
    "    df['Cohen\\'s d'] = cohens_d_values\n",
    "\n",
    "    alpha = 0.05\n",
    "    power = 0.8\n",
    "\n",
    "    z_alpha = norm.ppf(1 - alpha / 2) # z score for a two tailed test\n",
    "    z_beta = norm.ppf(power)            # power score\n",
    "\n",
    "    # use the formula for n\n",
    "    def calculate_n(std_dev, cohen_d):\n",
    "        return ((z_alpha + z_beta) ** 2 * (std_dev ** 2)) / (cohen_d ** 2)\n",
    "\n",
    "    sample_sizes = []\n",
    "    for index, row in df.iterrows():\n",
    "        n = calculate_n(row['Standard Deviation (MB/s)'], row['Cohen\\'s d'])\n",
    "        sample_sizes.append(round(n,2))\n",
    "\n",
    "    df['Sample Size (n)'] = sample_sizes\n",
    "\n",
    "    print(df[['IO_SIZE(Bytes)', 'Cohen\\'s d', 'Sample Size (n)']])\n",
    "    return df[['IO_SIZE(Bytes)', 'Cohen\\'s d', 'Sample Size (n)']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    IO_SIZE(Bytes)  Cohen's d  Sample Size (n)\n",
      "0             4096       5.62             2.29\n",
      "1             8192       2.34           296.95\n",
      "2            16384       1.37          9945.40\n",
      "3            32768       0.97        121128.19\n",
      "4            65536       0.76        971735.57\n",
      "5           131072       0.82       2010632.15\n",
      "6           262144       0.78       2334885.79\n",
      "7           524288       0.47      16262891.59\n",
      "8          1048576       0.55       9035544.29\n",
      "9          2097152       0.47      17451606.41\n",
      "10         4194304       0.74       3106626.08\n",
      "11         8388608       0.80       1692891.84\n",
      "12        16777216       1.08        412682.40\n",
      "13        33554432       1.21        268545.52\n",
      "14        67108864       0.73       1737146.67\n",
      "15       100663296       0.35      26656702.99\n",
      "    IO_SIZE(Bytes)  Cohen's d  Sample Size (n)\n",
      "0             4096       1.03          1589.93\n",
      "1             8192       0.56         52117.95\n",
      "2            16384       2.06          1287.64\n",
      "3            32768       3.77           332.29\n",
      "4            65536       0.98        168452.23\n",
      "5           131072       3.41          2415.41\n",
      "6           262144       4.30           976.44\n",
      "7           524288       0.87        539697.84\n",
      "8          1048576       2.19         13974.33\n",
      "9          2097152       1.53         61143.29\n",
      "10         4194304       0.83        642672.99\n",
      "11         8388608       1.60         41651.31\n",
      "12        16777216       0.37      10585812.84\n",
      "13        33554432       0.42       6135570.73\n",
      "14        67108864       0.32      19425719.90\n",
      "15       100663296       0.41       7945700.24\n",
      "    IO_SIZE(Bytes)  Cohen's d  Sample Size (n)\n",
      "0             4096       0.40         87061.13\n",
      "1             8192       0.30       1110706.56\n",
      "2            16384       0.29       4530870.42\n",
      "3            32768       0.28      16839836.70\n",
      "4            65536       0.27      59485600.88\n",
      "5           131072       0.34      70077493.03\n",
      "6           262144       0.66       5000931.29\n",
      "7           524288       2.27         39756.48\n",
      "8          1048576       1.33        324271.60\n",
      "9          2097152       3.21         10516.39\n",
      "10         4194304       1.92         75229.30\n",
      "11         8388608       1.75         78961.64\n",
      "12        16777216       0.70       2159808.70\n",
      "13        33554432       0.72       2036332.32\n",
      "14        67108864       0.66       2782141.63\n",
      "15       100663296       0.85       1048910.27\n",
      "    IO_SIZE(Bytes)  Cohen's d  Sample Size (n)\n",
      "0             4096       0.24        295636.88\n",
      "1             8192       0.14       3425514.02\n",
      "2            16384       4.88            28.74\n",
      "3            32768       3.39           366.72\n",
      "4            65536       1.76         12296.08\n",
      "5           131072       0.56       2124341.42\n",
      "6           262144       3.66          1499.09\n",
      "7           524288       1.67         32081.75\n",
      "8          1048576       1.42         61239.13\n",
      "9          2097152       0.71        961033.80\n",
      "10         4194304       1.57         40445.42\n",
      "11         8388608       2.47          6708.17\n",
      "12        16777216       1.78         22520.68\n",
      "13        33554432       3.18          2234.36\n",
      "14        67108864       1.99         14193.19\n",
      "15       100663296       2.52          5189.90\n",
      "    IO_SIZE(Bytes)  Cohen's d  Sample Size (n)\n",
      "0     4.096410e+03       0.27        202835.21\n",
      "1     4.096819e+03       0.26        186682.27\n",
      "2     4.096164e+03       0.21        376693.40\n",
      "3     4.096328e+03       0.18        693751.25\n",
      "4     4.096655e+03       0.19        681868.50\n",
      "..             ...        ...              ...\n",
      "75    1.048577e+06       2.52         28497.33\n",
      "76    1.048576e+06       1.09        754306.15\n",
      "77    1.048576e+06       1.42        278281.38\n",
      "78    1.048577e+06       1.39        322067.58\n",
      "79    1.048576e+06       2.00         81514.03\n",
      "\n",
      "[80 rows x 3 columns]\n",
      "    IO_SIZE(Bytes)  Cohen's d  Sample Size (n)\n",
      "0     4.096410e+03       0.79          5770.13\n",
      "1     4.096819e+03       0.36        105410.90\n",
      "2     4.096164e+03       0.40         47924.56\n",
      "3     4.096328e+03       0.46         23277.94\n",
      "4     4.096655e+03       0.76          4297.88\n",
      "..             ...        ...              ...\n",
      "75    1.048577e+06       1.14        355559.01\n",
      "76    1.048576e+06       1.61        108585.81\n",
      "77    1.048576e+06       1.28        286884.56\n",
      "78    1.048577e+06       1.73         97177.96\n",
      "79    1.048576e+06       1.10        673971.05\n",
      "\n",
      "[80 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "all_data = [size_read, size_write, random_read, random_write, stride_read, stride_write]\n",
    "\n",
    "data_labels = ['Size Read', 'Size Write', 'Random Read', 'Random Write', 'Stride Read', 'Stride Write']\n",
    "\n",
    "results = []\n",
    "\n",
    "for label, item in zip(data_labels, all_data):\n",
    "    result_df = calculate_sample_size(item)\n",
    "    result_df['Dataset'] = label  \n",
    "    results.append(result_df)\n",
    "\n",
    "final_results = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# send results to csv file\n",
    "final_results.to_csv('challenge_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
